{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9e0428-7b99-48d9-8ab1-0e8f7f5e450e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "# import GPUtil\n",
    "# import psutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c476cbf-40e5-4caa-ab99-e229947a8f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b718fa81-1ffc-438e-bd9e-412e8cac3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, gzip, os, hashlib\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/geohot/ai-notebooks/blob/master/mnist_from_scratch.ipynb\n",
    "def fetchMNISTFromURL(url):\n",
    "    \"\"\"This function loads and returns the training or testing sets of MNIST dataset (depending on the url passed).\n",
    "    \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    url: string\n",
    "        The proportion of the original training dataset that is used during the training process.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    fp = os.path.join('./datasets/mnist', hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            data = f.read()\n",
    "            print(type(gzip.decompress(data)))\n",
    "    else:\n",
    "        with open(fp, \"wb\") as f:\n",
    "            data = requests.get(url).content\n",
    "            f.write(data)\n",
    "    return np.frombuffer(gzip.decompress(data), dtype=np.uint8).copy()\n",
    "\n",
    "\n",
    "def fetchMNIST():\n",
    "    \"\"\"This function loads and returns the training and testing sets of the MNIST dataset.\n",
    "    \"\"\"\n",
    "    X_train_mnist = fetchMNISTFromURL(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "    y_train_mnist = fetchMNISTFromURL(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
    "    X_test_mnist = fetchMNISTFromURL(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "    y_test_mnist = fetchMNISTFromURL(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")[8:]\n",
    "    \n",
    "    return X_train_mnist, y_train_mnist, X_test_mnist, y_test_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a2879c-1c4e-4184-ac50-9dd87c2fa243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(training_size):\n",
    "    \"\"\"This function loads and preprocesses (i.e., pads) the MNIST dataset. The function returns\n",
    "    the training dataset (according to the passed training size), the testing dataset and the \n",
    "    larger testing dataset (i.e., the dataset that will be used during the inference phase).\n",
    "    \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    training_size: float\n",
    "        The proportion of the original training dataset that is used during the training process.\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_test, y_test = fetchMNIST()\n",
    "    \n",
    "    X_train = X_train[:int(training_size*X_train.shape[0])]\n",
    "    y_train = y_train[:X_train.shape[0]]\n",
    "    \n",
    "    X_test_ext = X_test.copy()\n",
    "    y_test_ext = y_test.copy()\n",
    "    print(X_test_ext.shape)\n",
    "    for j in range(100):\n",
    "        X_test_ext = np.append(X_test_ext, X_test.copy(), axis=0)\n",
    "        y_test_ext = np.append(y_test_ext, y_test.copy(), axis=0)\n",
    "    print(X_test_ext.shape)\n",
    "\n",
    "    X_train_padded = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_test_padded = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    X_test_padded_ext = X_test_ext.reshape(X_test_ext.shape[0], 28, 28, 1)\n",
    "\n",
    "    X_train_padded = np.pad(X_train_padded, ((0,0),(2,2),(2,2), (0,0)), 'constant')\n",
    "    X_test_padded = np.pad(X_test_padded, ((0,0),(2,2),(2,2), (0,0)), 'constant')\n",
    "    X_test_padded_ext = np.pad(X_test_padded_ext, ((0,0),(2,2),(2,2), (0,0)), 'constant')\n",
    "    \n",
    "    X_train_padded = np.array(X_train_padded / 255.0)\n",
    "    X_test_padded = np.array(X_test_padded / 255.0)\n",
    "    X_test_padded_ext = np.array(X_test_padded_ext / 255.0)\n",
    "    \n",
    "    return X_train_padded, y_train, X_test_padded, y_test, X_test_padded_ext, y_test_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e87b7b9-2e0a-4464-abf8-143d147b461d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load_and_preprocess_data(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076ffe04-a7c8-4d03-8259-34c701d30f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tarek\\AppData\\Local\\Temp/ipykernel_48276/988874731.py:23: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_dict = {\n",
    "    'cpu': {\n",
    "        'PyTorch': 'cpu',\n",
    "        'Keras': '/cpu:0',\n",
    "        'TensorFlow': '/CPU:0'\n",
    "    },\n",
    "    'gpu': {\n",
    "        'PyTorch': 'cuda',\n",
    "        'Keras': '/gpu:0',\n",
    "        'TensorFlow': '/GPU:0'\n",
    "    }\n",
    "}\n",
    "\n",
    "weight_initialization_dict = { \n",
    "    'xavier': {\n",
    "        'PyTorch': torch.nn.init.xavier_normal_,\n",
    "        'Keras': tf.keras.initializers.GlorotNormal,\n",
    "        'TensorFlow': tf.compat.v1.initializers.glorot_normal\n",
    "    },\n",
    "    'he': {\n",
    "        'PyTorch': torch.nn.init.kaiming_normal_,\n",
    "        'Keras': tf.keras.initializers.HeNormal,\n",
    "        'TensorFlow': tf.compat.v1.keras.initializers.he_normal\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b73470-a566-412e-885e-fbaf874ab931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'PyTorch': {},\n",
    "    'Keras': {},\n",
    "    'TensorFlow': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c24a91-8279-4d47-8815-c1ee23672fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe0c555-9cc4-4b7d-8be1-17be415cacce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = arguments.i\n",
    "training_size = arguments.training_size\n",
    "batch_size = arguments.batch_size\n",
    "n_epochs = arguments.n_epochs\n",
    "learning_rate = arguments.learning_rate\n",
    "data_type = arguments.data_type\n",
    "device = arguments.device\n",
    "weight_initialization = arguments.weight_initialization\n",
    "framework = arguments.framework\n",
    "dropout = arguments.dropout\n",
    "phase = arguments.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49f16b9-0d65-488c-85bc-36e865c250f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# training_size = 1\n",
    "# batch_size = 256\n",
    "# n_epochs = 10\n",
    "# learning_rate = 0.01\n",
    "# data_type = 'float32'\n",
    "# device = 'cpu'\n",
    "# weight_initialization = 'xavier'\n",
    "# framework = 'TensorFlow'\n",
    "# dropout = 0.25\n",
    "# phase = 'inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8561ec30-f55e-4505-b594-569be1edef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'lenet5_{}{}_{}ts_{}batch_{}epochs_{}lr_{}dtype_{}_{}wi_{}dp'.format(framework, i,\n",
    "                                                                              training_size, batch_size,\n",
    "                                                                              n_epochs, learning_rate, data_type,\n",
    "                                                                              device, weight_initialization, dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8827b7f5-1bfc-4351-a817-fcfb31d85428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the LSTM model dirrectory (i.e., the directory where the models are saved) does not exist, we create it.\n",
    "if not os.path.isdir('./models'):\n",
    "    os.mkdir('./models')\n",
    "if not os.path.isdir('./models/lenet5'):\n",
    "    os.mkdir('./models/lenet5')\n",
    "if not os.path.isdir('./models/lenet5/{}'.format(experiment)):\n",
    "    os.mkdir('./models/lenet5/{}'.format(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c504c4-256f-417e-afc1-c728d0819373",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./Results/lenet5/'):\n",
    "    os.mkdir('./Results/lenet5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a37a17-3b5f-4b92-9e60-fb1364c17f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'bytes'>\n",
      "<class 'bytes'>\n",
      "<class 'bytes'>\n",
      "(10000, 28, 28)\n",
      "(5010000, 28, 28)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.2 GiB for an array with shape (5010000, 32, 32, 1) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48276/3203895248.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_padded_ext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_ext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_and_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48276/2124280827.py\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(training_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mX_train_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_padded\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mX_test_padded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_padded\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mX_test_padded_ext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_padded_ext\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_train_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_padded_ext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_ext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 38.2 GiB for an array with shape (5010000, 32, 32, 1) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train_padded, y_train, X_test_padded, y_test, X_test_padded_ext, y_test_ext = load_and_preprocess_data(training_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93255d-28d0-4b3f-a332-438da0082bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "# import GPUtil\n",
    "# import psutil\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "collect_time = 0\n",
    "\n",
    "#Making sure the tensorflow doesn't take up all the VRAM available on GPU\n",
    "if device == 'gpu':\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# print('GPU mem: {}'.format((GPUtil.getGPUs()[0].memoryUsed / GPUtil.getGPUs()[0].memoryTotal) * 100))\n",
    "# print('CPU mem: {}'.format(psutil.virtual_memory().used / psutil.virtual_memory().total))\n",
    "\n",
    "\n",
    "\n",
    "#we try to minimize the randomness as much as possible\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "# tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "print('Training {}'.format(experiment))\n",
    "\n",
    "training_time = 0\n",
    "inference_time = 0\n",
    "accuracy = 0\n",
    "\n",
    "train_start_timestamp = 0\n",
    "train_end_timestamp = 0\n",
    "\n",
    "inference_start_timestamp = 0\n",
    "inference_end_timestamp = 0\n",
    "\n",
    "\n",
    "# X_train_mnist_temp = X_train_mnist[:int(training_size*len(X_train_mnist))]\n",
    "# y_train_mnist = y_train_mnist[:len(X_train_mnist_temp)]\n",
    "\n",
    "# training_mnist = X_train_mnist_temp.reshape(X_train_mnist_temp.shape[0], 28, 28, 1)\n",
    "# testing_mnist = X_test_mnist.reshape(X_test_mnist.shape[0], 28, 28, 1)\n",
    "\n",
    "# training_mnist = np.pad(training_mnist, ((0,0),(2,2),(2,2), (0,0)), 'constant')\n",
    "# testing_mnist = np.pad(testing_mnist, ((0,0),(2,2),(2,2), (0,0)), 'constant')\n",
    "\n",
    "# if data_type == 'mixed':\n",
    "#     training_mnist_norm = np.array(training_mnist / 255.0, dtype=np.float16)\n",
    "#     testing_mnist_norm = np.array(testing_mnist / 255.0, dtype=np.float16)\n",
    "# else:\n",
    "#     training_mnist_norm = np.array(training_mnist / 255.0)\n",
    "#     testing_mnist_norm = np.array(testing_mnist / 255.0)\n",
    "\n",
    "if framework == 'PyTorch':\n",
    "    \n",
    "    \n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torch.nn import CrossEntropyLoss\n",
    "    from torch.optim import SGD\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    from torchvision.transforms import ToTensor\n",
    "    from torch.autograd import Variable\n",
    "    from torchvision import transforms\n",
    "\n",
    "    import pytorch_lenet5\n",
    "    \n",
    "    pytorch_train_loader, pytorch_test_loader, pytorch_test_loader_ext = pytorch_lenet5.generate_pytorch_dataloader(X_train_padded, X_test_padded,\n",
    "                                                                                                                  X_test_padded_ext, y_train,\n",
    "                                                                                                                  y_test, y_test_ext, batch_size,\n",
    "                                                                                                                  device_dict[device][framework])\n",
    "\n",
    "    model = pytorch_lenet5.PyTorchLenet5Mod(weight_initialization_dict[weight_initialization][framework], dropout)\n",
    "    model = model.to(device_dict[device][framework])\n",
    "    \n",
    "    if phase == 'training':\n",
    "        from torch.optim import SGD\n",
    "        \n",
    "        optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "        training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = pytorch_lenet5.pytorch_training_phase(model, optimizer,\n",
    "                                                                                                                                  pytorch_train_loader, pytorch_test_loader,\n",
    "                                                                                                                                  n_epochs, device_dict[device][framework],\n",
    "                                                                                                                                  data_type, experiment)\n",
    "    elif phase == 'inference':\n",
    "        inference_start_timestamp, inference_end_timestamp = pytorch_lenet5.pytorch_inference_phase(model, experiment, pytorch_test_loader_ext,\n",
    "                                                                                                  device_dict[device][framework], data_type)\n",
    "    \n",
    "    #We take the mean time the model takes to infer a single sample.\n",
    "    inference_time /= X_test_padded.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "if framework == 'Keras':\n",
    "\n",
    "    import os\n",
    "    os.environ['TF2_BEHAVIOR'] = '1'\n",
    "    import tensorflow as tf\n",
    "\n",
    "    import keras_lenet5\n",
    "    \n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    if data_type == 'mixed':\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "    \n",
    "    if phase == 'training':\n",
    "    \n",
    "        model = keras_lenet5.initialize_keras_lenet5(weight_initialization_dict[weight_initialization][framework], dropout)\n",
    "    \n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "        \n",
    "        training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = keras_lenet5.keras_training_phase(model, optimizer,\n",
    "                                                                                                                              loss_fn, X_train_padded,\n",
    "                                                                                                                              y_train, X_test_padded,\n",
    "                                                                                                                              y_test, batch_size, n_epochs,\n",
    "                                                                                                                              device_dict[device][framework],\n",
    "                                                                                                                              data_type, experiment)\n",
    "    elif phase == 'inference':\n",
    "        inference_start_timestamp, inference_end_timestamp = keras_lenet5.keras_inference_phase(X_test_padded_ext, y_test_ext,\n",
    "                                                                                              batch_size, device_dict[device][framework],\n",
    "                                                                                              data_type, experiment)\n",
    "\n",
    "\n",
    "\n",
    "    # if device == 'gpu':\n",
    "    #     training_time, inference_time, accuracy, cpu_utilization, cpu_mem, gpu_utilization, gpu_mem = KerasLenet5(experiment, training_mnist_norm, y_train_mnist, testing_mnist_norm, y_test_mnist, batch_size, n_epochs, learning_rate, data_type, device_dict[device][framework], weight_initialization_dict[weight_initialization][framework])\n",
    "    # else:\n",
    "    #     training_time, inference_time, accuracy, cpu_utilization, cpu_mem, _, _ = KerasLenet5(experiment, training_mnist_norm, y_train_mnist, testing_mnist_norm, y_test_mnist, batch_size, n_epochs, learning_rate, data_type, device_dict[device][framework], weight_initialization_dict[weight_initialization][framework])\n",
    "\n",
    "    # keras_lenet5_model.save('./models/{}'.format(experiment))\n",
    "\n",
    "    print('{}\\tTraining time: {}\\tInference time: {}\\tAccuracy: {}'.format(experiment, training_time,\n",
    "                                                                          inference_time, accuracy))\n",
    "\n",
    "if framework == 'TensorFlow':\n",
    "    #the first version of tensorflow needs to be used, as tensorflow 2.0 uses keras by default\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "    tf.compat.v1.set_random_seed(0)\n",
    "    \n",
    "    import tensorflow_lenet5\n",
    "\n",
    "    \n",
    "    \n",
    "    with tf.device(device_dict[device][framework]):\n",
    "        with tf.compat.v1.variable_scope(name_or_scope='TensorFlowLenet5', reuse=tf.compat.v1.AUTO_REUSE,\n",
    "                                         initializer=weight_initialization_dict[weight_initialization][framework]):\n",
    "\n",
    "            model = tensorflow_lenet5.TensorFlowLenet5Mod(weight_initialization_dict[weight_initialization][framework], dropout)\n",
    "            \n",
    "            #Collecting the lenghts of the sequences (note that all the sequences are of the same length as they\n",
    "            #have been padded).\n",
    "            # lens_train = np.array([len(xi) for xi in X_train_padded], dtype='int32')\n",
    "            # lens_test = np.array([len(xi) for xi in X_test_padded], dtype='int32')\n",
    "            # lens_test_ext = np.array([len(xi) for xi in X_test_padded_ext], dtype='int32')\n",
    "            if phase == 'training':\n",
    "            # (model, learning_rate, X_train_padded,\n",
    "            #           y_train, X_test_padded,\n",
    "            #           y_test, batch_size, n_epochs, device, data_type,\n",
    "            #           experiment):\n",
    "\n",
    "                training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = tensorflow_lenet5.tensorflow_training_phase(model, learning_rate, X_train_padded, y_train,\n",
    "                                                                                                                                                  X_test_padded, y_test, batch_size, n_epochs,\n",
    "                                                                                                                                                  device_dict[device][framework], data_type, experiment)\n",
    "            elif phase == 'inference':\n",
    "                \n",
    "                inference_start_timestamp, inference_end_timestamp = tensorflow_lenet5.tensorflow_inference_phase(model, X_test_padded_ext,\n",
    "                                                                                                                  y_test_ext, batch_size,\n",
    "                                                                                                                  device_dict[device][framework],\n",
    "                                                                                                                  data_type, experiment)\n",
    "\n",
    "#Writing the results collected during the training or the inference phase\n",
    "if phase == 'training':\n",
    "    results = {\n",
    "        'training_time': training_time,\n",
    "        'inference_time': inference_time,\n",
    "        'accuracy': accuracy,\n",
    "        'train_start_timestamp': train_start_timestamp,\n",
    "        'train_end_timestamp': train_end_timestamp\n",
    "    }\n",
    "\n",
    "    with open('./Results/lenet5/{}.txt'.format(experiment), 'w+', encoding='utf-8') as f:\n",
    "        for fieldName in results.keys():\n",
    "            f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))\n",
    "elif phase == 'inference':\n",
    "    results = {\n",
    "        'inference_start_timestamp': inference_start_timestamp,\n",
    "        'inference_end_timestamp': inference_end_timestamp\n",
    "    }\n",
    "    \n",
    "    with open('./Results/lenet5/{}.txt'.format(experiment), 'a', encoding='utf-8') as f:\n",
    "        for fieldName in results.keys():\n",
    "            f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))\n",
    "\n",
    "print(results)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca374c76-e738-4af1-9e51-bff2196b21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0e98f-9e90-4909-a3ef-2fe45730bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(is_complete=True):\n",
    "    \"\"\"This function reads the file that contains the results of the evaluation of the model.\n",
    "    If this function is called after the inference phase is done (i.e., is_complete=True), then\n",
    "    the function returns a dictionary containing the training time, the inference time, the accuracy,\n",
    "    the training and the inference time stamps and the hardware utilization metrics. On the other hand,\n",
    "    if the function is called before the inference phase (i.e., is_complete=False), then the function\n",
    "    will return a dictionary containing all the above except for the hardware utilization metrics.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    is_complete: Boolean\n",
    "        This boolean indicates whether the inference phase is done or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    with open('./Results/lenet5/{}.txt'.format(experiment), 'r', encoding='utf-8') as f:\n",
    "        \n",
    "        s = f.read()\n",
    "\n",
    "        results['training_time'] = float(s.split('training_time = ')[1].split('\\n\\n')[0])\n",
    "        results['inference_time'] = float(s.split('inference_time = ')[1].split('\\n\\n')[0])\n",
    "        results['accuracy'] = float(s.split('accuracy = ')[1].split('\\n\\n')[0])\n",
    "\n",
    "        try:\n",
    "            results['train_start_timestamp'] = datetime.datetime.strptime(s.split('train_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                          '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['train_start_timestamp'] = datetime.datetime.strptime(s.split('train_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                          '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        try:\n",
    "            results['train_end_timestamp'] = datetime.datetime.strptime(s.split('train_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                        '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['train_end_timestamp'] = datetime.datetime.strptime(s.split('train_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                        '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            results['inference_start_timestamp'] = datetime.datetime.strptime(s.split('inference_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                              '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['inference_start_timestamp'] = datetime.datetime.strptime(s.split('inference_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                              '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        try:\n",
    "            results['inference_end_timestamp'] = datetime.datetime.strptime(s.split('inference_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                            '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            new_res['inference_end_timestamp'] = datetime.datetime.strptime(s.split('inference_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                            '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            \n",
    "        if is_complete:\n",
    "            results['cpu_utilization_train'] = [float(samp) for samp in s.split('cpu_utilization_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['cpu_mem_train'] = [float(samp) for samp in s.split('cpu_mem_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_utilization_train'] = [float(samp) for samp in s.split('gpu_utilization_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_mem_train'] = [float(samp) for samp in s.split('gpu_mem_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "\n",
    "            results['cpu_utilization_infer'] = [float(samp) for samp in s.split('cpu_utilization_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['cpu_mem_infer'] = [float(samp) for samp in s.split('cpu_mem_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_utilization_infer'] = [float(samp) for samp in s.split('gpu_utilization_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_mem_infer'] = [float(samp) for samp in s.split('gpu_mem_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a20f6-ce23-47f1-bf3d-319188095319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sampled_metrics():\n",
    "    \"\"\"This function collects the hardware utilization metrics that corresond to the training and inference\n",
    "    processes according to the time stamps of the training and inference (which are collected from the results\n",
    "    file) and the time stamps at which the corresponding metric was sampled.\n",
    "    \"\"\"\n",
    "    results = read_results(is_complete=False)\n",
    "\n",
    "    results['cpu_utilization_train'] = []\n",
    "    results['cpu_mem_train'] = []\n",
    "    results['gpu_utilization_train'] = []\n",
    "    results['gpu_mem_train'] = []\n",
    "    \n",
    "    results['cpu_utilization_infer'] = []\n",
    "    results['cpu_mem_infer'] = []\n",
    "    results['gpu_utilization_infer'] = []\n",
    "    results['gpu_mem_infer'] = []\n",
    "\n",
    "\n",
    "    with open('./Results/lenet5/metric_sampling.csv', 'r', encoding='utf-8') as csvFile:\n",
    "        csvReader = csv.reader(csvFile, delimiter=',')\n",
    "\n",
    "        for row in csvReader:\n",
    "            if row[0] == 'CPU Utilization':\n",
    "                continue\n",
    "\n",
    "            sample_timestamp_str = row[4]\n",
    "\n",
    "            try:\n",
    "                sample_timestamp_datetime = datetime.datetime.strptime(sample_timestamp_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "            except:\n",
    "                sample_timestamp_datetime = datetime.datetime.strptime(sample_timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "            if results['inference_end_timestamp'] < sample_timestamp_datetime:\n",
    "                break\n",
    "            \n",
    "            if results['inference_start_timestamp'] <= sample_timestamp_datetime and results['inference_end_timestamp'] >= sample_timestamp_datetime:\n",
    "                results['cpu_utilization_infer'].append(float(row[0]))\n",
    "                results['cpu_mem_infer'].append(float(row[1]))\n",
    "\n",
    "                results['gpu_utilization_infer'].append(float(row[2]))\n",
    "                results['gpu_mem_infer'].append(float(row[3]))\n",
    "                continue\n",
    "\n",
    "            if results['train_start_timestamp'] > sample_timestamp_datetime:\n",
    "                continue\n",
    "\n",
    "            if results['train_end_timestamp'] < sample_timestamp_datetime:\n",
    "                continue\n",
    "\n",
    "            \n",
    "                \n",
    "            results['cpu_utilization_train'].append(float(row[0]))\n",
    "            results['cpu_mem_train'].append(float(row[1]))\n",
    "\n",
    "            results['gpu_utilization_train'].append(float(row[2]))\n",
    "            results['gpu_mem_train'].append(float(row[3]))\n",
    "\n",
    "\n",
    "    with open('./Results/lenet5/{}.txt'.format(experiment), 'w+', encoding='utf-8') as f:\n",
    "        for fieldName in results.keys():\n",
    "            f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f6824-48b4-4e04-bc9d-4ebcedb3df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only collect the hardware utilization metrics after the inference phase\n",
    "if phase == 'inference':\n",
    "    collect_sampled_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846502-ecf0-4608-b4b9-c78f0336ebc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
