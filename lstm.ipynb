{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44be5617-c816-4cd0-97d2-c1adc96214d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3e7b4f-6eb5-4e45-96a6-62805e30d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IMDB_Dataset(T.utils.data.Dataset):\n",
    "#   # each line: 20 token IDs, 0 or 1 label. space delimited\n",
    "#   def __init__(self, src_file):\n",
    "#     all_xy = np.loadtxt(src_file, usecols=range(0,21),\n",
    "#       delimiter=\" \", comments=\"#\", dtype=np.int64)\n",
    "#     tmp_x = all_xy[:,0:20]   # cols [0,20) = [0,19]\n",
    "#     tmp_y = all_xy[:,20]     # all rows, just col 20\n",
    "#     self.x_data = T.tensor(tmp_x, dtype=T.int64) \n",
    "#     self.y_data = T.tensor(tmp_y, dtype=T.int64)  # CE loss\n",
    "\n",
    "#   def __len__(self):\n",
    "#     return len(self.x_data)\n",
    "\n",
    "#   def __getitem__(self, idx):\n",
    "#     token_ids = self.x_data[idx]\n",
    "#     trgts = self.y_data[idx] \n",
    "#     return (token_ids, trgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8d1802-5390-402f-9ad2-03350972bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.legacy import datasets\n",
    "\n",
    "# train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341d71cc-955a-4e49-8bde-84ea6cd1ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[[1, 2, 3], [1, 2, 3], [1, 2, 3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fc75a7-a71c-4525-9dc7-19e842d84526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test#.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb614b8-1548-425b-b259-71d78d97a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192829337\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*torch.__config__.show().split(\"\\n\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9483e176-9ad5-48f6-a842-a2e96ce76283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We try to minimize the randomness as much as possible by setting the random seeds\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c24a91-8279-4d47-8815-c1ee23672fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe0c555-9cc4-4b7d-8be1-17be415cacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the set of configurations from the file created by the RunExperiments script\n",
    "i = arguments.i\n",
    "training_size = arguments.training_size\n",
    "batch_size = arguments.batch_size\n",
    "n_epochs = arguments.n_epochs\n",
    "learning_rate = arguments.learning_rate\n",
    "data_type = arguments.data_type\n",
    "device = arguments.device\n",
    "weight_initialization = arguments.weight_initialization\n",
    "framework = arguments.framework\n",
    "dropout = arguments.dropout\n",
    "phase = arguments.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915c622f-6f9e-42e4-a107-519fda303eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'lstm_{}{}_{}ts_{}batch_{}epochs_{}lr_{}dtype_{}_{}wi_{}dp'.format(framework, i, training_size,\n",
    "                                                                                batch_size, n_epochs,\n",
    "                                                                                learning_rate, data_type, device,\n",
    "                                                                                weight_initialization, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32428d84-3d67-4b31-a8c6-d86d96162a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure tensorflow/keras do not reserve all the VRAM available on GPU\n",
    "if device == 'gpu':\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6a1e30-56cc-432f-9782-118c7a1c4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(training_size, vocab_size=10000, review_length=500):\n",
    "    \"\"\"This function loads and preprocesses (i.e., pads) the IMDB movie review dataset. The\n",
    "    function returns the training dataset (according to the passed training size),\n",
    "    the testing dataset and the larger testing dataset (i.e., the dataset that will be used during\n",
    "    the inference phase).\n",
    "    \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    training_size: float\n",
    "        The proportion of the original training dataset that is used during the training process.\n",
    "    vocab_size: int\n",
    "        The number of words that are to be considered among the words that used most frequently.\n",
    "    review_lenght: int\n",
    "        The maximum lenght of the movie reviews loaded.\n",
    "    \"\"\"\n",
    "    #Loading the IMDB movie review dataset\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "    #Setting the training set to correspond to the training size in the configurations\n",
    "    X_train = X_train[:int(training_size*X_train.shape[0])]\n",
    "    y_train = y_train[:X_train.shape[0]]\n",
    "\n",
    "    #Setting up the larger dataset that will be used during the inference phase.\n",
    "    X_test_ext = X_test.copy()\n",
    "    y_test_ext = y_test.copy()\n",
    "    for j in range(8):\n",
    "        X_test_ext = np.append(X_test_ext, X_test.copy(), axis=0)\n",
    "        y_test_ext = np.append(y_test_ext, y_test.copy(), axis=0)\n",
    "\n",
    "    #Padding the reviews so they are all the same lenght\n",
    "    X_train_padded = keras.preprocessing.sequence.pad_sequences(X_train, maxlen = review_length)\n",
    "    X_test_padded = keras.preprocessing.sequence.pad_sequences(X_test, maxlen = review_length)\n",
    "    X_test_padded_ext = keras.preprocessing.sequence.pad_sequences(X_test_ext, maxlen = review_length)\n",
    "    \n",
    "    return X_train_padded, y_train, X_test_padded, y_test, X_test_padded_ext, y_test_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd70a9ca-54f9-449b-b909-1c335f4fe66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tarek\\AppData\\Local\\Temp/ipykernel_31768/1248941715.py:25: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Defining dictionaries to set the device and weight initialization configurations\n",
    "#to their corresponding values in the DL frameworks\n",
    "device_dict = {\n",
    "    'cpu': {\n",
    "        'PyTorch': 'cpu',\n",
    "        'Keras': '/cpu:0',\n",
    "        'TensorFlow': '/CPU:0'\n",
    "    },\n",
    "    'gpu': {\n",
    "        'PyTorch': 'cuda',\n",
    "        'Keras': '/gpu:0',\n",
    "        'TensorFlow': '/GPU:0'\n",
    "    }\n",
    "}\n",
    "\n",
    "weight_initialization_dict = { \n",
    "    'xavier': {\n",
    "        'PyTorch': torch.nn.init.xavier_normal_,\n",
    "        'Keras': tf.keras.initializers.GlorotNormal,\n",
    "        'TensorFlow': tf.compat.v1.initializers.glorot_normal\n",
    "    },\n",
    "    'he': {\n",
    "        'PyTorch': torch.nn.init.kaiming_normal_,\n",
    "        'Keras': tf.keras.initializers.HeNormal,\n",
    "        'TensorFlow': tf.compat.v1.keras.initializers.he_normal\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a242007-b797-4d01-b1a1-a338edc8ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the LSTM model dirrectory (i.e., the directory where the models are saved) does not exist, we create it.\n",
    "if not os.path.isdir('./models'):\n",
    "    os.mkdir('./models')\n",
    "if not os.path.isdir('./models/lstm'):\n",
    "    os.mkdir('./models/lstm')\n",
    "if not os.path.isdir('./models/lstm/{}'.format(experiment)):\n",
    "    os.mkdir('./models/lstm/{}'.format(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdaa1058-c183-47fb-8ceb-5d306e1518cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The set of fixed hyper-parameters\n",
    "vocab_size = 10000\n",
    "review_length = 500\n",
    "embedding_size = 32\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea0c104a-73e9-44d1-83c9-12e6a30ac25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\tarek\\anaconda3\\envs\\dl_testing_env\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\tarek\\anaconda3\\envs\\dl_testing_env\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "#Loading the IMDB dataset\n",
    "X_train_padded, y_train, X_test_padded, y_test, X_test_padded_ext, y_test_ext = load_and_preprocess_data(training_size,\n",
    "                                                                                                         vocab_size=10000,\n",
    "                                                                                                         review_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a93255d-28d0-4b3f-a332-438da0082bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lstm_Keras0_0.5ts_256batch_3epochs_0.005lr_mixeddtype_gpu_xavierwi_0dp\n",
      "879/879 [==============================] - 14s 14ms/step - loss: 0.5632 - accuracy: 0.7108\n",
      "Accuracy: 0.7107599973678589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training {}'.format(experiment))\n",
    "\n",
    "training_time = 0\n",
    "inference_time = 0\n",
    "accuracy = 0\n",
    "\n",
    "train_start_timestamp = 0\n",
    "train_end_timestamp = 0\n",
    "\n",
    "inference_start_timestamp = 0\n",
    "inference_end_timestamp = 0\n",
    "\n",
    "\n",
    "\n",
    "if framework == 'PyTorch':\n",
    "    import pytorch_lstm\n",
    "    \n",
    "    pytorch_train_loader, pytorch_test_loader, pytorch_test_loader_ext = pytorch_lstm.generate_pytorch_dataloader(X_train_padded, X_test_padded,\n",
    "                                                                                                                  X_test_padded_ext, y_train,\n",
    "                                                                                                                  y_test, y_test_ext, batch_size,\n",
    "                                                                                                                  device_dict[device][framework],\n",
    "                                                                                                                  review_length=500)\n",
    "\n",
    "    model = pytorch_lstm.PyTorchLSTMMod(weight_initialization_dict[weight_initialization][framework],\n",
    "                                        vocab_size, embedding_size, hidden_size, dropout)\n",
    "    model = model.to(device_dict[device][framework])\n",
    "    \n",
    "    if phase == 'training':\n",
    "        from torch.optim import Adam\n",
    "        \n",
    "        optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "        training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = pytorch_lstm.pytorch_training_phase(model, optimizer,\n",
    "                                                                                                                                  pytorch_train_loader, pytorch_test_loader,\n",
    "                                                                                                                                  n_epochs, device_dict[device][framework],\n",
    "                                                                                                                                  data_type, experiment)\n",
    "    elif phase == 'inference':\n",
    "        inference_start_timestamp, inference_end_timestamp = pytorch_lstm.pytorch_inference_phase(model, experiment, pytorch_test_loader_ext,\n",
    "                                                                                                  device_dict[device][framework], data_type)\n",
    "    \n",
    "    #We take the mean time the model takes to infer a single sample.\n",
    "    inference_time /= X_test_padded.shape[0]\n",
    "\n",
    "\n",
    "if framework == 'Keras':\n",
    "    os.environ['TF2_BEHAVIOR'] = '1'\n",
    "    import tensorflow as tf\n",
    "\n",
    "    if device == 'gpu':\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    import keras_lstm\n",
    "    \n",
    "#     if data_type == 'mixed':\n",
    "#         policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "#         tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "    \n",
    "    if phase == 'training':\n",
    "    \n",
    "        model = keras_lstm.initialize_keras_lstm(weight_initialization_dict[weight_initialization][framework],\n",
    "                                                 vocab_size, review_length, embedding_size, hidden_size,\n",
    "                                                 dropout)\n",
    "    \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        loss_fn = tf.keras.losses.binary_crossentropy\n",
    "        \n",
    "        training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = keras_lstm.keras_training_phase(model, optimizer,\n",
    "                                                                                                                              loss_fn, X_train_padded,\n",
    "                                                                                                                              y_train, X_test_padded,\n",
    "                                                                                                                              y_test, batch_size, n_epochs,\n",
    "                                                                                                                              device_dict[device][framework],\n",
    "                                                                                                                              data_type, experiment)\n",
    "    elif phase == 'inference':\n",
    "        inference_start_timestamp, inference_end_timestamp = keras_lstm.keras_inference_phase(X_test_padded_ext, y_test_ext,\n",
    "                                                                                              batch_size, device_dict[device][framework],\n",
    "                                                                                              data_type, experiment)\n",
    "\n",
    "if framework == 'TensorFlow':\n",
    "    #the first version of tensorflow needs to be used, as tensorflow 2.0 uses keras by default\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "    tf.compat.v1.set_random_seed(0)\n",
    "    \n",
    "    import tensorflow_lstm\n",
    "\n",
    "    \n",
    "    \n",
    "    with tf.device(device_dict[device][framework]):\n",
    "        with tf.compat.v1.variable_scope(name_or_scope='TensorFlowLSTM', reuse=tf.compat.v1.AUTO_REUSE,\n",
    "                                         initializer=weight_initialization_dict[weight_initialization][framework]):\n",
    "\n",
    "            model = tensorflow_lstm.TensorFlowLSTMMod(weight_initialization_dict[weight_initialization][framework], vocab_size,\n",
    "                                                      embedding_size, hidden_size, dropout, device_dict[device][framework])\n",
    "            \n",
    "            #Collecting the lenghts of the sequences (note that all the sequences are of the same length as they\n",
    "            #have been padded).\n",
    "            lens_train = np.array([len(xi) for xi in X_train_padded], dtype='int32')\n",
    "            lens_test = np.array([len(xi) for xi in X_test_padded], dtype='int32')\n",
    "            lens_test_ext = np.array([len(xi) for xi in X_test_padded_ext], dtype='int32')\n",
    "            if phase == 'training':\n",
    "            \n",
    "                training_time, inference_time, accuracy, train_start_timestamp, train_end_timestamp = tensorflow_lstm.tensorflow_training_phase(model, learning_rate,\n",
    "                                                                                                                                                review_length,\n",
    "                                                                                                                                                X_train_padded,\n",
    "                                                                                                                                                lens_train, y_train,\n",
    "                                                                                                                                                X_test_padded, \n",
    "                                                                                                                                                lens_test, y_test, \n",
    "                                                                                                                                                batch_size, n_epochs,\n",
    "                                                                                                                                                device_dict[device][framework],\n",
    "                                                                                                                                                data_type, experiment)\n",
    "            elif phase == 'inference':\n",
    "                \n",
    "                inference_start_timestamp, inference_end_timestamp = tensorflow_lstm.tensorflow_inference_phase(model, review_length,\n",
    "                                                                                                                X_test_padded_ext,\n",
    "                                                                                                                lens_test_ext, y_test_ext,\n",
    "                                                                                                                batch_size,\n",
    "                                                                                                                device_dict[device][framework],\n",
    "                                                                                                                data_type, experiment)\n",
    "\n",
    "                \n",
    "#Writing the results collected during the training or the inference phase\n",
    "if phase == 'training':\n",
    "    results = {\n",
    "        'training_time': training_time,\n",
    "        'inference_time': inference_time,\n",
    "        'accuracy': accuracy,\n",
    "        'train_start_timestamp': train_start_timestamp,\n",
    "        'train_end_timestamp': train_end_timestamp\n",
    "    }\n",
    "\n",
    "    # with open('./Results/lstm/{}.txt'.format(experiment), 'w+', encoding='utf-8') as f:\n",
    "    #     for fieldName in results.keys():\n",
    "    #         f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))\n",
    "elif phase == 'inference':\n",
    "    results = {\n",
    "        'inference_start_timestamp': inference_start_timestamp,\n",
    "        'inference_end_timestamp': inference_end_timestamp\n",
    "    }\n",
    "    \n",
    "    # with open('./Results/lstm/{}.txt'.format(experiment), 'a', encoding='utf-8') as f:\n",
    "    #     for fieldName in results.keys():\n",
    "    #         f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "058d6469-aae0-4609-9252-3c5acb38f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21fa87-4569-4362-8941-998e3215bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(is_complete=True):\n",
    "    \"\"\"This function reads the file that contains the results of the evaluation of the model.\n",
    "    If this function is called after the inference phase is done (i.e., is_complete=True), then\n",
    "    the function returns a dictionary containing the training time, the inference time, the accuracy,\n",
    "    the training and the inference time stamps and the hardware utilization metrics. On the other hand,\n",
    "    if the function is called before the inference phase (i.e., is_complete=False), then the function\n",
    "    will return a dictionary containing all the above except for the hardware utilization metrics.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    is_complete: Boolean\n",
    "        This boolean indicates whether the inference phase is done or not.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    with open('./Results/lstm/{}.txt'.format(experiment), 'r', encoding='utf-8') as f:\n",
    "        \n",
    "        s = f.read()\n",
    "\n",
    "        results['training_time'] = float(s.split('training_time = ')[1].split('\\n\\n')[0])\n",
    "        results['inference_time'] = float(s.split('inference_time = ')[1].split('\\n\\n')[0])\n",
    "        results['accuracy'] = float(s.split('accuracy = ')[1].split('\\n\\n')[0])\n",
    "\n",
    "        try:\n",
    "            results['train_start_timestamp'] = datetime.datetime.strptime(s.split('train_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                          '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['train_start_timestamp'] = datetime.datetime.strptime(s.split('train_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                          '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        try:\n",
    "            results['train_end_timestamp'] = datetime.datetime.strptime(s.split('train_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                        '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['train_end_timestamp'] = datetime.datetime.strptime(s.split('train_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                        '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            results['inference_start_timestamp'] = datetime.datetime.strptime(s.split('inference_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                              '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            results['inference_start_timestamp'] = datetime.datetime.strptime(s.split('inference_start_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                              '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        try:\n",
    "            results['inference_end_timestamp'] = datetime.datetime.strptime(s.split('inference_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                            '%Y-%m-%d %H:%M:%S.%f')\n",
    "        except:\n",
    "            new_res['inference_end_timestamp'] = datetime.datetime.strptime(s.split('inference_end_timestamp = ')[1].split('\\n\\n')[0],\n",
    "                                                                            '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            \n",
    "        if is_complete:\n",
    "            results['cpu_utilization_train'] = [float(samp) for samp in s.split('cpu_utilization_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['cpu_mem_train'] = [float(samp) for samp in s.split('cpu_mem_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_utilization_train'] = [float(samp) for samp in s.split('gpu_utilization_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_mem_train'] = [float(samp) for samp in s.split('gpu_mem_train = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "\n",
    "            results['cpu_utilization_infer'] = [float(samp) for samp in s.split('cpu_utilization_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['cpu_mem_infer'] = [float(samp) for samp in s.split('cpu_mem_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_utilization_infer'] = [float(samp) for samp in s.split('gpu_utilization_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "            results['gpu_mem_infer'] = [float(samp) for samp in s.split('gpu_mem_infer = [')[1].split('\\n\\n')[0].replace(']', '').split(', ')]\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c213a-af84-46de-95c4-8f7ad83666b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sampled_metrics():\n",
    "    \"\"\"This function collects the hardware utilization metrics that corresond to the training and inference\n",
    "    processes according to the time stamps of the training and inference (which are collected from the results\n",
    "    file) and the time stamps at which the corresponding metric was sampled.\n",
    "    \"\"\"\n",
    "    results = read_results(is_complete=False)\n",
    "\n",
    "    results['cpu_utilization_train'] = []\n",
    "    results['cpu_mem_train'] = []\n",
    "    results['gpu_utilization_train'] = []\n",
    "    results['gpu_mem_train'] = []\n",
    "    \n",
    "    results['cpu_utilization_infer'] = []\n",
    "    results['cpu_mem_infer'] = []\n",
    "    results['gpu_utilization_infer'] = []\n",
    "    results['gpu_mem_infer'] = []\n",
    "\n",
    "\n",
    "    with open('./Results/lstm/metric_sampling.csv', 'r', encoding='utf-8') as csvFile:\n",
    "        csvReader = csv.reader(csvFile, delimiter=',')\n",
    "\n",
    "        for row in csvReader:\n",
    "            if row[0] == 'CPU Utilization':\n",
    "                continue\n",
    "\n",
    "            sample_timestamp_str = row[4]\n",
    "\n",
    "            try:\n",
    "                sample_timestamp_datetime = datetime.datetime.strptime(sample_timestamp_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "            except:\n",
    "                sample_timestamp_datetime = datetime.datetime.strptime(sample_timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "            if results['inference_end_timestamp'] < sample_timestamp_datetime:\n",
    "                break\n",
    "            \n",
    "            if results['inference_start_timestamp'] <= sample_timestamp_datetime and results['inference_end_timestamp'] >= sample_timestamp_datetime:\n",
    "                results['cpu_utilization_infer'].append(float(row[0]))\n",
    "                results['cpu_mem_infer'].append(float(row[1]))\n",
    "\n",
    "                results['gpu_utilization_infer'].append(float(row[2]))\n",
    "                results['gpu_mem_infer'].append(float(row[3]))\n",
    "                continue\n",
    "\n",
    "            if results['train_start_timestamp'] > sample_timestamp_datetime:\n",
    "                continue\n",
    "\n",
    "            if results['train_end_timestamp'] < sample_timestamp_datetime:\n",
    "                continue\n",
    "\n",
    "            \n",
    "                \n",
    "            results['cpu_utilization_train'].append(float(row[0]))\n",
    "            results['cpu_mem_train'].append(float(row[1]))\n",
    "\n",
    "            results['gpu_utilization_train'].append(float(row[2]))\n",
    "            results['gpu_mem_train'].append(float(row[3]))\n",
    "\n",
    "\n",
    "    with open('./Results/lstm/{}.txt'.format(experiment), 'w+', encoding='utf-8') as f:\n",
    "        for fieldName in results.keys():\n",
    "            f.write('{} = {}\\n\\n'.format(fieldName, results[fieldName]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66a484-35c9-4812-aa3f-b0dd8c8864f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only collect the hardware utilization metrics after the inference phase\n",
    "if phase == 'inference':\n",
    "    collect_sampled_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
